#!/usr/bin/perl

use strict;
use warnings;
use Fcntl qw(LOCK_EX LOCK_NB);
use File::Slurp 'read_file';
use IO::Handle;

my $dir = ".";

################################################################################

sub first_matching_file {
    my ($dir, %sub) = @_;
    opendir(my $dh, $dir) or die "Failed to open dir '$dir' for reading: $!\n";
    while (defined(my $file = readdir($dh))) {
        my ($base, $ext) = $file =~ /^(.*?)([.][^.]+|)$/;
        if (exists $sub{$ext}) {
            my @value = $sub{$ext}->($base, $ext);
            return @value if @value;
        }
        next;
    }
    return ();
}

################################################################################

# Functions to send to first_matching_file(), each processes one file
# extension. Return () to continue processing, return something (whatever) to
# have this returned from first_matching_file().
my %unlocked_todo_file = (
    # Cleanup of orphaned .log files.
    ".log" => sub {
        my ($base, $ext) = @_;
        if (not -e "$base.todo") {
            unlink("$base.log") or die "Failed to delete file '$base.log': $!\n";
            warn "Deleted orphaned log file: $base.log\n";
        }
        return ();
    },
    # Return filehandle + basename + filename of unlocked .todo file.
    ".todo" => sub {
        my ($base, $ext) = @_;
        open(my $fh, "<", "$base.todo")  or die "Failed to open job file '$base.todo' for reading: $!";
        flock($fh, LOCK_EX | LOCK_NB) or do {
            warn "Ignoring running job: $base.todo\n";
            return ();
        };
        return ($fh, $base, "$base$ext");
    },
);


#
# Multiple Processes and Race Conditions
# ======================================
# 1. An exclusive lock on 'batch.todo' file must exist throughout the
#    'batch.log' file's existence. (We can then use the lock to determine if a
#    job is currently in progress, without any race conditions.)
#
# 2. 'batch.log' must be deleted only after 'batch.todo' has been marked as
#    done by renaming it 'batch.done'. This way, if the 'batch.todo' job ever
#    crashes, it can always be resumed (since the logfile will always exist).
#
my $count = 0;
my @ignore_file;
while (my ($todo, $base, $file) =
           first_matching_file($dir, %unlocked_todo_file)) {
    my $todo_file = "$dir/$base.todo";
    my $done_file = "$dir/$base.done";
    my $log_file  = "$dir/$base.log";

    # Read previously processed ids from log (if any).
    my %already_done = map {
        ($_ => 1);
    } read_file($log_file, chomp => 1, err_mode => 'quiet');
    if (%already_done) {
        warn "Resuming unfinished job: $file\n";
    } elsif ($! ne "No such file or directory") {
        die "Failed to open file '$log_file' for reading: $!\n";
    }

    open(my $log, ">>", $log_file)
        or die "Failed to open file '$log_file' for appending: $!";
    $log->autoflush();

    print "PROCESSING: '$file'\n";
    $count += 1;
    while (defined(my $id = <$todo>)) {
        chomp($id);
        if (exists $already_done{$id}) {
            print "    '$id' -- done by previous job\n";
            next;
        }
        print "    '$id' -- processing\n";

        # index id   OR die "Failed to index!!"
        sleep 1;

        print $log "$id\n";
        $already_done{$id} = 1;
    }
    close($log)                    or die "Failed to close file '$log_file' after writing: $!\n";
    # Below order is super-important for atomicness!
    # (Rename '.todo' -> '.done' first, then delete logfile, close '.todo' last.)
    rename($todo_file, $done_file) or die "Failed to rename file '$todo_file' to '$done_file': $!\n";
    unlink($log_file)              or die "Failed to delete file '$log_file': $!\n";
    close($todo)                   or die "Failed to close file '$todo_file' after reading: $!\n";
}

print $count == 0
    ? "No unstarted jobs found in '$dir'\n"
    : "Processed $count jobs in '$dir'\n";

#[eof]
